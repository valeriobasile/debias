# -*- coding: utf-8 -*-
"""[gmail] debias

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V1qCP8t11e8w3debs8yNlJc5T3qM7OuP
"""

!pip install -q keras-bert keras-rectified-adam
!pip install tensorflow==1.15
#!pip install gensim

import os
import numpy as np
import codecs
from keras_bert import load_trained_model_from_checkpoint, Tokenizer
from tqdm import tqdm
import pickle
import csv
import keras
from keras_radam import RAdam
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score
import pandas as pd
from tensorflow.python.keras import backend as K
import tensorflow as tf
from gensim.corpora.dictionary import Dictionary
from gensim.models.ldamodel import LdaModel
from gensim.matutils import sparse2full
from pprint import pprint

from google.colab import drive, auth
drive.mount('/content/drive', force_remount=True)

SEQ_LEN = 100
BATCH_SIZE = 8
EPOCHS = 10
LR = 1e-6
N_TOPICS = 10

bert_model = {
        'model': 'uncased_L-12_H-768_A-12',
        'config': 'bert_config.json',
        'checkpoint': 'bert_model.ckpt',
        'vocab': 'vocab.txt'
}    

base_path = '/content/drive/My Drive/Colab Notebooks'
data_path = os.path.join(base_path, 'data')
model_path = os.path.join(base_path, 'bert-models')
pretrained_path = os.path.join(model_path, 'uncased_L-12_H-768_A-12')
config_path = os.path.join(pretrained_path, 'bert_config.json')
checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')
vocab_path = os.path.join(pretrained_path, 'vocab.txt')

fulldata_path = os.path.join(data_path, 'debias/hateval2019_target.csv')
topics_train_path = os.path.join(data_path, 'debias/topics_train_{0}.csv'.format(N_TOPICS))
topics_dev_path = os.path.join(data_path, 'debias/topics_dev_{0}.csv'.format(N_TOPICS))
topics_test_path = os.path.join(data_path, 'debias/topics_test_{0}.csv'.format(N_TOPICS))

token_dict = {}
with codecs.open(vocab_path, 'r', 'utf8') as reader:
    for line in reader:
        token = line.strip()
        token_dict[token] = len(token_dict)

with open(fulldata_path, 'r') as f:
    reader = csv.DictReader(f)

tokenizer = Tokenizer(token_dict)

def load_data(path, target, language, split):
    global tokenizer
    indices, sentiments = [], []
    sentences = []
    instance_ids = []
    with open(path, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row['set'] == split and row['language'] == language and row['target'] in target:
                ids, segments = tokenizer.encode(row['text'], max_len=SEQ_LEN)
                indices.append(ids)
                sentiments.append(eval(row['HS']))
                tokens = tokenizer.tokenize(row['text'])
                sentences.append(tokens[1:-1])
                instance_ids.append(row['id'])

    items = list(zip(indices, sentiments))
    np.random.shuffle(items)
    indices, sentiments = zip(*items)
    indices = np.array(indices)
    mod = indices.shape[0] % BATCH_SIZE
    if mod > 0:
        indices, sentiments = indices[:-mod], sentiments[:-mod]
    return [indices, np.zeros_like(indices)], np.array(sentiments), instance_ids, sentences
  
train_x, train_y, train_ids, train_sentences = load_data(fulldata_path, ["mig", "mis"], 'en', 'train')
dev_x, dev_y, dev_ids, dev_sentences = load_data(fulldata_path, ["mig", "mis"], 'en', 'dev')
test_x, test_y, test_ids, test_sentences = load_data(fulldata_path, ["mig", "mis"], 'en', 'test')

id2word = Dictionary(train_sentences)
corpus_train = [id2word.doc2bow(text) for text in train_sentences]
lda_model = LdaModel(corpus=corpus_train,
                                    id2word=id2word,
                                    num_topics=N_TOPICS, 
                                    random_state=100,
                                    passes=50,
                                    alpha='auto')

topics_train = lda_model.get_document_topics(corpus_train)
corpus_dev = [id2word.doc2bow(text) for text in dev_sentences]
topics_dev = lda_model.get_document_topics(corpus_dev)
corpus_test = [id2word.doc2bow(text) for text in test_sentences]
topics_test = lda_model.get_document_topics(corpus_test)

with open(topics_train_path, 'w') as fo:
    writer = csv.writer(fo)
    writer.writerow(['id']+['topic_{0}'.format(i) for i in range(N_TOPICS)])
    for i, vector in enumerate(topics_train):
        row = [train_ids[i]] + [str(x) for x in sparse2full(vector, N_TOPICS)]
        writer.writerow(row)
with open(topics_dev_path, 'w') as fo:
    writer = csv.writer(fo)
    writer.writerow(['id']+['topic_{0}'.format(i) for i in range(N_TOPICS)])
    for i, vector in enumerate(topics_dev):
        row = [dev_ids[i]] + [str(x) for x in sparse2full(vector, N_TOPICS)]
        writer.writerow(row)
with open(topics_test_path, 'w') as fo:
    writer = csv.writer(fo)
    writer.writerow(['id']+['topic_{0}'.format(i) for i in range(N_TOPICS)])
    for i, vector in enumerate(topics_test):
        row = [test_ids[i]] + [str(x) for x in sparse2full(vector, N_TOPICS)]
        writer.writerow(row)
pprint(lda_model.print_topics(50))

def read_topics(path):
    t = []
    with open(path, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            t.append(np.array([row['topic_{0}'.format(i)] for i in range(N_TOPICS)]))
    return np.array(t)

train_t = read_topics(topics_train_path)
dev_t = read_topics(topics_dev_path)
test_t = read_topics(topics_test_path)

def evaluate(predicts, gold):
        accuracy = (np.sum(gold == predicts) / gold.shape[0])
        tp = 0
        fp = 0
        tn = 0
        fn = 0
        for c in range(len(np.unique(gold))):
            for g, p in zip(gold, predicts):
                if g == p:
                    if p==c:
                        tp+=1
                    else:
                        tn+=1
                else:
                    if p==c:
                        fp+=1
                    else:
                        fn+=1
        if tp+fp == 0:
            microp = 0.0
        else:
            microp = tp/(tp+fp)
        if tp+fn == 0:
            micror = 0.0
        else:
            micror = tp/(tp+fn)
        if microp+micror == 0.0:
            microf1 = 0.0
        else:
            microf1 = (2*microp*micror)/(microp+micror)

        report = classification_report(gold, predicts, output_dict=True)
        df = pd.DataFrame(report)
        eval_values = []
        for l in [str(x) for x in range(len(np.unique(gold)))]:
            if not l in df:
                eval_values.extend([0,0,0])
            else:
                eval_values.extend([
                    df[l]['precision'],
                    df[l]['recall'],
                    df[l]['f1-score']
                ])
        eval_values.extend([
                    df['macro avg']['precision'],
                    df['macro avg']['recall'],
                    df['macro avg']['f1-score']
        ])
        #eval_values.extend([microp, micror, microf1])
        eval_values.extend([accuracy])
        return eval_values

ALPHA = 0.6
SEED = 2
from numpy.random import seed
seed(SEED)

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))
    
def debias_loss(y_true, y_pred, from_logits=False, axis=-1):
    idx1 = tf.Variable([[[i,0]] for i in range(BATCH_SIZE)])
    idx2 = tf.Variable([[[i,0], [i,1]] for i in range(BATCH_SIZE)])
    label_true = tf.gather_nd(y_true, idx1)
    label_pred = tf.gather_nd(y_pred, idx2)

    idx_t1 = tf.Variable([[[i,j] for j in range(1,N_TOPICS+1)] for i in range(BATCH_SIZE)])
    idx_t2 = tf.Variable([[[i,j] for j in range(2,N_TOPICS+2)] for i in range(BATCH_SIZE)])
    topic_true = tf.gather_nd(y_true, idx_t1)
    topic_pred = tf.gather_nd(y_pred, idx_t2)

    #return K.sparse_categorical_crossentropy(label_true, label_pred, from_logits=from_logits, axis=axis)
    return (ALPHA*K.sparse_categorical_crossentropy(label_true, label_pred, from_logits=from_logits, axis=axis)) + ((1-ALPHA) * keras.metrics.cosine_proximity(topic_true, topic_pred))
 

def cos_distance(y_true, y_pred):
    def l2_normalize(x, axis):
        norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=True))
        return K.maximum(x, K.epsilon()) / K.maximum(norm, K.epsilon())
    y_true = l2_normalize(y_true, axis=-1)
    y_pred = l2_normalize(y_pred, axis=-1)
    return -K.mean(y_true * y_pred, axis=-1)

def cos_similarity(y_true, y_pred):
    def l2_normalize(x, axis):
        norm = K.sqrt(K.sum(K.square(x), axis=axis, keepdims=True))
        return K.maximum(x, K.epsilon()) / K.maximum(norm, K.epsilon())
    y_true = l2_normalize(y_true, axis=-1)
    y_pred = l2_normalize(y_pred, axis=-1)
    return K.mean(y_true * y_pred, axis=-1)
    
def debias_acc(y_true, y_pred):
    idx1 = tf.Variable([[[i,0]] for i in range(BATCH_SIZE)])
    idx2 = tf.Variable([[[i,0], [i,1]] for i in range(BATCH_SIZE)])
    
    label_true = tf.gather_nd(y_true, idx1)
    label_pred = tf.argmax(tf.gather_nd(y_pred, idx2), axis=1)

    # idx_t1 = tf.Variable([[[i,j] for j in range(1,26)] for i in range(BATCH_SIZE)])
    # idx_t2 = tf.Variable([[[i,j] for j in range(2,27)] for i in range(BATCH_SIZE)])
    # topic_true = tf.gather_nd(y_true, idx_t1)
    # topic_pred = tf.gather_nd(y_true, idx_t2)
    
    #return K.sparse_categorical_crossentropy(label_true, label_pred, from_logits=from_logits, axis=axis) + keras.metrics.cosine_proximity(topic_true, topic_pred)
    #return keras.metrics.accuracy(label_true, label_pred)
    return f1_m(tf.cast(label_true, tf.float32), tf.cast(label_pred, tf.float32))
    #return f1_score(label_true, label_pred , average="macro")

model = load_trained_model_from_checkpoint(
    config_path,
    checkpoint_path,
    training=True,
    trainable=True,
    seq_len=SEQ_LEN,
)

inputs = model.inputs[:2]
dense = model.get_layer('NSP-Dense').output
dropout = keras.layers.Dropout(0.5)(dense)
outputs_t = keras.layers.Dense(N_TOPICS, name="topic")(dropout)
outputs = keras.layers.Dense(2, name="label")(dropout)

model = keras.models.Model(inputs, [outputs, outputs_t])
#model.summary()
losses = {
	"label": "sparse_categorical_crossentropy",
	"topic": cos_similarity
    }
metrics = {
	"label": "accuracy",
	"topic": cos_similarity
    }
lossWeights = {"label": ALPHA, "topic": 1-ALPHA}

model.compile(
    #RAdam(lr=LR),
    Adam(lr=LR),
    loss=losses, 
    metrics=metrics,
)



train_yt = np.hstack((np.asmatrix(train_y).transpose(), train_t))
dev_yt = np.hstack((np.asmatrix(dev_y).transpose(), dev_t))

callbacks = [EarlyStopping(monitor='val_loss', patience=10)]

history = model.fit(
    train_x,
    {"label": train_y, "topic": train_t},
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=True,
    callbacks=callbacks,
    validation_data=(dev_x, {"label": dev_y, "topic": dev_t}),
    )   

import matplotlib.pyplot as plt

# # summarize history for loss
plt.plot(history.history['label_loss'])
plt.plot(history.history['val_label_loss'])
plt.title('label_loss')
plt.ylabel('label_loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# # summarize history for accuracy
plt.plot(history.history['label_accuracy'])
plt.plot(history.history['val_label_accuracy'])
plt.title('label_accuracy')
plt.ylabel('label_accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

predicts = model.predict(dev_x, verbose=False)
pred = predicts[0].argmax(axis=1)
scores = evaluate(pred, dev_y)
print (confusion_matrix(pred, dev_y))
print ("\t".join(['{0:.3f}'.format(s) for s in scores]))
predictions_path = os.path.join(data_path, 'debias/predictions/dev_{0}_lr{1}_e{2}_t{3}_a{4}_s{5}.txt'.format("en-mig+mis", LR, EPOCHS, N_TOPICS, ALPHA, SEED))
with open(predictions_path, "w") as fo:
    for p in pred:
        fo.write("{0}\n".format(p))
        
predicts = model.predict(test_x, verbose=False)
pred = predicts[0].argmax(axis=1)
scores = evaluate(pred, test_y)
print ("\t".join(['{0:.3f}'.format(s) for s in scores]))
print (confusion_matrix(pred, test_y))

predictions_path = os.path.join(data_path, 'debias/predictions/test_{0}_lr{1}_e{2}_t{3}_a{4}_s{5}.txt'.format("en-mig+mis", LR, EPOCHS, N_TOPICS, ALPHA, SEED))
with open(predictions_path, "w") as fo:
    for p in pred:
        fo.write("{0}\n".format(p))